dataset:
  save_path: "../../../../dataset/detect/"
  # fn: "emri_asd_v0.5_50_120_1yr.hdf5"
  # fn: "emri_asd_v0.5_70_170_1yr.hdf5"
  # fn: "emri_asd_v0.5_100_240_1yr.hdf5"
  # fn: "emri_asd_v0.5_50_120_1yr_M_snr.hdf5"
  # fn: "emri_asd_v0.5_50_120_1yr_M_p0.hdf5"
  # fn: "emri_asd_v0.5_50_120_1yr_M_e0.hdf5"
  # fn: "emri_asd_v0.5_50_120_1yr_M_a.hdf5"
  # fn: "emri_asd_v0.5_50_120_1yr_M_Y0.hdf5"
  # ===========================================
  fn: emri_asd_test.hdf5
dataloader:
  batch_size: 256
  num_workers: 8
  # reduce: 2

training:
  test_only: False
  checkpoint_dir: "./results/2023-07-10/09-46-49/best_model.pth" # 4k
  gpu: 0
  n_epoch: 50
  # loss_fn: "bce_with_logits"
  loss_fn: "cross_entropy"
  optimizer_type: "adam"
  optimizer_kwargs:
    lr: 5e-5
    weight_decay: 1e-3
  scheduler_type: "plateau"
  scheduler_kwargs:
    mode: "min"
    factor: 0.5
    patience: 5
    threshold: 1e-4
  result_dir: "./results//${now:%Y-%m-%d}/${now:%H-%M-%S}"
  result_fn: "inf_result_100_240_1k.npy"
  use_wandb: False

net:
  input_channels: 2
  n_classes: 2
  n_hidden: 128
  n_levels: 10
  kernel_size: 3
  num_classes: 2
  dropout: 0